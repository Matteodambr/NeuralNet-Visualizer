"""
NN_PLOTTING_UTILITIES - A module for plotting neural network architectures.

This module provides classes to represent and visualize neural network structures.
Currently supports feedforward neural networks with fully connected layers.
"""

from typing import List, Optional, Dict, Any
from dataclasses import dataclass
from enum import Enum
from abc import ABC, abstractmethod


class NetworkType(Enum):
    """Enumeration of supported neural network types."""
    FEEDFORWARD = "feedforward"
    # Future types can be added here:
    # CONVOLUTIONAL = "convolutional"
    # RECURRENT = "recurrent"
    # TRANSFORMER = "transformer"


class LayerType(Enum):
    """Enumeration of supported layer types."""
    FULLY_CONNECTED = "fully_connected"
    INPUT_VECTOR = "input_vector"
    INPUT_IMAGE = "input_image"
    OUTPUT_VECTOR = "output_vector"
    OUTPUT_GENERIC = "output_generic"
    # Future types can be added here:
    # CONVOLUTIONAL = "convolutional"
    # POOLING = "pooling"
    # DROPOUT = "dropout"
    # BATCH_NORM = "batch_norm"


class Layer(ABC):
    """
    Abstract base class for all layer types.
    
    All layer implementations must inherit from this class and implement
    the required abstract methods.
    
    Attributes:
        layer_type (LayerType): The type of this layer.
        name (Optional[str]): Human-readable name for the layer.
        layer_id (str): Unique identifier for this layer (auto-generated).
    """
    
    def __init__(
        self,
        layer_type: LayerType,
        name: Optional[str] = None,
        layer_id: Optional[str] = None
    ):
        """
        Initialize a Layer object.
        
        Args:
            layer_type (LayerType): The type of this layer.
            name (Optional[str]): Human-readable name for the layer.
            layer_id (Optional[str]): Unique identifier. If None, auto-generates UUID.
        """
        self.layer_type = layer_type
        self.name = name
        
        # Generate a unique ID if not provided
        if layer_id is None:
            import uuid
            self.layer_id = str(uuid.uuid4())
        else:
            self.layer_id = layer_id
    
    @abstractmethod
    def get_output_size(self) -> int:
        """
        Get the output size (number of output units/neurons) of this layer.
        
        Returns:
            int: The output size of the layer.
        """
        pass
    
    @abstractmethod
    def __str__(self) -> str:
        """Return a human-readable string representation of the layer."""
        pass
    
    def __repr__(self) -> str:
        """Return a developer-friendly string representation of the layer."""
        return f"{self.__class__.__name__}(id='{self.layer_id[:8]}...', name='{self.name}')"


@dataclass
class FullyConnectedLayer(Layer):
    """
    Represents a fully connected (dense) layer in a neural network.
    
    A fully connected layer connects every neuron from the previous layer to every
    neuron in this layer. This is the most common type of layer in feedforward networks.
    
    Attributes:
        num_neurons (int): Number of neurons in this layer.
        activation (Optional[str]): Activation function name (e.g., 'relu', 'sigmoid', 'tanh', 'softmax').
        name (Optional[str]): Human-readable name for the layer.
        layer_id (str): Unique identifier for this layer (auto-generated).
        use_bias (bool): Whether this layer uses bias terms. Defaults to True.
        neuron_labels (Optional[List[str]]): Text labels for each neuron (supports LaTeX).
        label_position (str): Position of labels relative to neurons ('left' or 'right'). Default: 'left'.
    
    Example:
        >>> layer = FullyConnectedLayer(num_neurons=128, activation="relu", name="Hidden1")
        >>> print(layer.get_output_size())
        128
        >>> 
        >>> # Layer with LaTeX labels
        >>> input_layer = FullyConnectedLayer(
        ...     num_neurons=3,
        ...     name="Input",
        ...     neuron_labels=[r"$x_1$", r"$x_2$", r"$x_3$"],
        ...     label_position="left"
        ... )
    """
    num_neurons: int
    activation: Optional[str] = None
    name: Optional[str] = None
    layer_id: Optional[str] = None
    use_bias: bool = True
    neuron_labels: Optional[List[str]] = None
    label_position: str = "left"
    
    def __post_init__(self):
        """Validate the layer configuration after initialization."""
        if self.num_neurons <= 0:
            raise ValueError("Number of neurons must be positive")
        
        # Validate neuron_labels if provided
        if self.neuron_labels is not None:
            if len(self.neuron_labels) != self.num_neurons:
                raise ValueError(
                    f"Number of neuron_labels ({len(self.neuron_labels)}) must match "
                    f"num_neurons ({self.num_neurons})"
                )
        
        # Validate label_position
        if self.label_position not in ("left", "right"):
            raise ValueError("label_position must be 'left' or 'right'")
        
        # Initialize the base Layer class
        super().__init__(
            layer_type=LayerType.FULLY_CONNECTED,
            name=self.name,
            layer_id=self.layer_id
        )
    
    def get_output_size(self) -> int:
        """
        Get the output size of this fully connected layer.
        
        Returns:
            int: Number of neurons (output units) in this layer.
        """
        return self.num_neurons
    
    def __str__(self) -> str:
        """Return a human-readable string representation of the layer."""
        parts = [f"FullyConnected({self.num_neurons} neurons)"]
        if self.activation:
            parts.append(f"activation={self.activation}")
        if self.name:
            parts.append(f"name='{self.name}'")
        if not self.use_bias:
            parts.append("no_bias")
        return ", ".join(parts)
    
    def __repr__(self) -> str:
        """Return a developer-friendly string representation of the layer."""
        return (
            f"FullyConnectedLayer(neurons={self.num_neurons}, "
            f"activation={self.activation}, name='{self.name}', "
            f"id='{self.layer_id[:8]}...')"
        )


class InputLayer(Layer):
    """
    Abstract base class for all input layer types.
    
    Input layers are automatically treated as root layers (no parents) when added
    to a network. They represent the entry points for data into the network.
    
    Subclasses:
        - VectorInput: For 1D vector inputs (like tabular data)
        - ImageInput: For 2D/3D image inputs (future)
    """
    
    @property
    def is_input_layer(self) -> bool:
        """Mark this as an input layer for automatic root detection."""
        return True


@dataclass
class VectorInput(InputLayer):
    """
    Represents a vector (1D) input layer for the neural network.
    
    This is used for tabular/structured data where the input is a 1D vector of features.
    VectorInput layers are automatically treated as root layers (no parents).
    
    Attributes:
        num_features (int): Number of input features (vector dimensions).
        name (Optional[str]): Human-readable name for the layer.
        layer_id (str): Unique identifier for this layer (auto-generated).
        neuron_labels (Optional[List[str]]): Text labels for each neuron (supports LaTeX).
        label_position (str): Position of labels relative to neurons ('left' or 'right').
    
    Example:
        >>> input_layer = VectorInput(num_features=10, name="Input")
        >>> print(input_layer.get_output_size())
        10
        >>> 
        >>> # With LaTeX labels
        >>> input_layer = VectorInput(
        ...     num_features=3,
        ...     name="Features",
        ...     neuron_labels=[r"$x_1$", r"$x_2$", r"$x_3$"],
        ...     label_position="left"
        ... )
    """
    num_features: int
    name: Optional[str] = None
    layer_id: Optional[str] = None
    neuron_labels: Optional[List[str]] = None
    label_position: str = "left"
    
    def __post_init__(self):
        """Validate the layer configuration after initialization."""
        if self.num_features <= 0:
            raise ValueError("Number of features must be positive")
        
        # Validate neuron_labels if provided
        if self.neuron_labels is not None:
            if len(self.neuron_labels) != self.num_features:
                raise ValueError(
                    f"Number of neuron_labels ({len(self.neuron_labels)}) must match "
                    f"num_features ({self.num_features})"
                )
        
        # Validate label_position
        if self.label_position not in ("left", "right"):
            raise ValueError("label_position must be 'left' or 'right'")
        
        # Initialize the base Layer class
        super().__init__(
            layer_type=LayerType.INPUT_VECTOR,
            name=self.name,
            layer_id=self.layer_id
        )
    
    @property
    def num_neurons(self) -> int:
        """Alias for num_features to maintain compatibility with plotting."""
        return self.num_features
    
    def get_output_size(self) -> int:
        """
        Get the output size of this input layer.
        
        Returns:
            int: Number of features (output units) in this layer.
        """
        return self.num_features
    
    def __str__(self) -> str:
        """Return a human-readable string representation of the layer."""
        parts = [f"VectorInput({self.num_features} features)"]
        if self.name:
            parts.append(f"name='{self.name}'")
        return ", ".join(parts)
    
    def __repr__(self) -> str:
        """Return a developer-friendly string representation of the layer."""
        return (
            f"VectorInput(features={self.num_features}, name='{self.name}', "
            f"id='{self.layer_id[:8]}...')"
        )

@dataclass
class ImageInput(InputLayer):
    """
    Represents an image input layer for the neural network.
    
    This is used for image data (2D/3D) inputs, typically for CNN architectures.
    ImageInput layers are automatically treated as root layers (no parents).
    
    The layer can display in two modes:
    - Text mode: Shows a rounded rectangle with custom text
    - Image mode: Displays an actual image (with color and channel options)
    
    Attributes:
        height (int): Height of the input image in pixels.
        width (int): Width of the input image in pixels.
        channels (int): Number of channels (1 for BW, 3 for RGB). Default: 3.
        name (Optional[str]): Human-readable name for the layer.
        layer_id (str): Unique identifier for this layer (auto-generated).
        
        # Display options
        display_mode (str): How to render the layer - 'text' or 'image'.
                           Default: 'text'.
        custom_text (Optional[str]): Text to display when display_mode='text'. If None, 
                                     shows dimension info. Supports LaTeX.
        custom_text_size (float): Font size for custom text. Default: 12.
        custom_size (Optional[float]): Custom size for the rectangle. If provided, overrides
                                      the automatic aspect ratio-based sizing. Useful for
                                      controlling the visual size of the input layer.
        
        # Image options (when display_mode is 'image')
        image_path (Optional[str]): Path or URL to the image file.
        magnification (float): Magnification factor for image cropping (>1 zooms in). Default: 1.0.
        translation_x (float): Horizontal offset from center (-1 to 1, where 1 = half width). Default: 0.
        translation_y (float): Vertical offset from center (-1 to 1, where 1 = half height). Default: 0.
        color_mode (str): 'bw' or 'rgb' - whether to display as black & white or RGB.
                         Default: 'rgb' if channels==3, 'bw' if channels==1.
        separate_channels (bool): When True and color_mode='rgb', displays 3 overlapped rectangles
                                 (one per channel). When False, displays single image. Default: False.
        
        # Styling options
        rounded_corners (bool): Whether to use rounded corners for the rectangle(s). Default: True.
        corner_radius (float): Radius of rounded corners (used by plotting). Default: 0.15.
    
    Example:
        >>> # Simple text display
        >>> img_input = ImageInput(height=224, width=224, channels=3, name="Input Image")
        
        >>> # With custom text
        >>> img_input = ImageInput(
        ...     height=224, width=224, channels=3,
        ...     display_mode='text',
        ...     custom_text=r"$224 \\times 224 \\times 3$",
        ...     custom_text_size=14
        ... )
        
        >>> # Display actual image (single)
        >>> img_input = ImageInput(
        ...     height=224, width=224, channels=3,
        ...     display_mode='image',
        ...     image_path='https://example.com/cat.jpg',
        ...     color_mode='rgb',
        ...     magnification=1.5,
        ...     translation_x=0.2
        ... )
        
        >>> # Display RGB channels separately
        >>> img_input = ImageInput(
        ...     height=224, width=224, channels=3,
        ...     display_mode='image',
        ...     image_path='path/to/image.jpg',
        ...     color_mode='rgb',
        ...     separate_channels=True
        ... )
        
        >>> # Display as black and white
        >>> img_input = ImageInput(
        ...     height=224, width=224, channels=1,
        ...     display_mode='image',
        ...     image_path='color_image.jpg',
        ...     color_mode='bw'
        ... )
    """
    height: int
    width: int
    channels: int = 3
    name: Optional[str] = None
    layer_id: Optional[str] = None
    
    # Display options
    display_mode: str = "text"
    custom_text: Optional[str] = None
    custom_text_size: float = 12
    custom_size: Optional[float] = None  # Custom size for the rectangle (overrides aspect ratio scaling)
    
    # Image options
    image_path: Optional[str] = None
    magnification: float = 1.0
    translation_x: float = 0.0
    translation_y: float = 0.0
    color_mode: Optional[str] = None
    separate_channels: bool = False
    
    # Styling options
    rounded_corners: bool = True
    corner_radius: float = 0.15
    
    def __post_init__(self):
        """Validate the layer configuration after initialization."""
        # Validate dimensions
        if self.height <= 0 or self.width <= 0:
            raise ValueError("Image dimensions (height, width) must be positive")
        if self.channels not in (1, 3):
            raise ValueError("Channels must be 1 (BW) or 3 (RGB)")
        
        # Validate display_mode
        if self.display_mode not in ("text", "image"):
            raise ValueError(
                "display_mode must be 'text' or 'image'"
            )
        
        # Validate that image_path is provided for image mode
        if self.display_mode == "image" and self.image_path is None:
            raise ValueError(
                "image_path must be provided when display_mode='image'"
            )
        
        # Validate magnification
        if self.magnification <= 0:
            raise ValueError("Magnification must be positive")
        
        # Validate translation range
        if not (-1 <= self.translation_x <= 1):
            raise ValueError("translation_x must be between -1 and 1")
        if not (-1 <= self.translation_y <= 1):
            raise ValueError("translation_y must be between -1 and 1")
        
        # Set default color_mode based on channels if not specified
        if self.color_mode is None:
            self.color_mode = "rgb" if self.channels == 3 else "bw"
        
        # Validate color_mode
        if self.color_mode not in ("rgb", "bw"):
            raise ValueError("color_mode must be 'rgb' or 'bw'")
        
        # Validate consistency: separate_channels only makes sense for RGB
        if self.separate_channels and self.color_mode != "rgb":
            raise ValueError(
                "separate_channels=True requires color_mode='rgb'"
            )
        
        # Validate consistency: separate_channels requires channels=3
        if self.separate_channels and self.channels != 3:
            raise ValueError(
                "separate_channels=True requires channels=3"
            )
        
        # Initialize the base Layer class
        super().__init__(
            layer_type=LayerType.INPUT_IMAGE,
            name=self.name,
            layer_id=self.layer_id
        )
    
    @property
    def num_neurons(self) -> int:
        """Alias for compatibility with plotting. Returns flattened size."""
        return self.height * self.width * self.channels
    
    def get_output_size(self) -> int:
        """
        Get the output size of this input layer.
        
        Returns:
            int: Total number of pixels (height * width * channels).
        """
        return self.height * self.width * self.channels
    
    def __str__(self) -> str:
        """Return a human-readable string representation of the layer."""
        parts = [f"ImageInput({self.height}×{self.width}×{self.channels})"]
        if self.name:
            parts.append(f"name='{self.name}'")
        if self.display_mode != "text":
            parts.append(f"mode='{self.display_mode}'")
        return ", ".join(parts)
    
    def __repr__(self) -> str:
        """Return a developer-friendly string representation of the layer."""
        return (
            f"ImageInput(height={self.height}, width={self.width}, channels={self.channels}, "
            f"mode='{self.display_mode}', name='{self.name}', id='{self.layer_id[:8]}...')"
        )


class OutputLayer(Layer):
    """
    Abstract base class for all output layer types.
    
    Output layers are automatically treated as leaf layers (no children) when added
    to a network. They represent the final output of the network.
    
    Subclasses:
        - VectorOutput: For output layers with individual neurons (like fully connected)
        - GenericOutput: For generic output layers displayed as a rounded box with text
    """
    
    @property
    def is_output_layer(self) -> bool:
        """Mark this as an output layer for automatic leaf detection."""
        return True


@dataclass
class VectorOutput(OutputLayer):
    """
    Represents a vector output layer with individual neurons (similar to fully connected layer).
    
    This output layer displays individual neurons and is suitable for classification,
    regression, or any task where you want to show the individual output units.
    It inherits all customization options from fully connected layers.
    
    Attributes:
        num_neurons (int): Number of output neurons.
        activation (Optional[str]): Activation function name (e.g., 'sigmoid', 'softmax', 'linear').
        name (Optional[str]): Human-readable name for the layer.
        layer_id (str): Unique identifier for this layer (auto-generated).
        use_bias (bool): Whether this layer uses bias terms. Defaults to True.
        neuron_labels (Optional[List[str]]): Text labels for each neuron (supports LaTeX).
        label_position (str): Position of labels relative to neurons ('left' or 'right'). Default: 'right'.
    
    Example:
        >>> output_layer = VectorOutput(num_neurons=10, activation="softmax", name="Output")
        >>> print(output_layer.get_output_size())
        10
        >>> 
        >>> # Output layer with LaTeX labels
        >>> output_layer = VectorOutput(
        ...     num_neurons=3,
        ...     name="Classes",
        ...     neuron_labels=[r"$y_1$", r"$y_2$", r"$y_3$"],
        ...     label_position="right"
        ... )
    """
    num_neurons: int
    activation: Optional[str] = None
    name: Optional[str] = None
    layer_id: Optional[str] = None
    use_bias: bool = True
    neuron_labels: Optional[List[str]] = None
    label_position: str = "right"
    
    def __post_init__(self):
        """Validate the layer configuration after initialization."""
        if self.num_neurons <= 0:
            raise ValueError("Number of neurons must be positive")
        
        # Validate neuron_labels if provided
        if self.neuron_labels is not None:
            if len(self.neuron_labels) != self.num_neurons:
                raise ValueError(
                    f"Number of neuron_labels ({len(self.neuron_labels)}) must match "
                    f"num_neurons ({self.num_neurons})"
                )
        
        # Validate label_position
        if self.label_position not in ("left", "right"):
            raise ValueError("label_position must be 'left' or 'right'")
        
        # Initialize the base Layer class
        super().__init__(
            layer_type=LayerType.OUTPUT_VECTOR,
            name=self.name,
            layer_id=self.layer_id
        )
    
    def get_output_size(self) -> int:
        """
        Get the output size of this output layer.
        
        Returns:
            int: Number of neurons (output units) in this layer.
        """
        return self.num_neurons
    
    def __str__(self) -> str:
        """Return a human-readable string representation of the layer."""
        parts = [f"VectorOutput({self.num_neurons} neurons)"]
        if self.activation:
            parts.append(f"activation={self.activation}")
        if self.name:
            parts.append(f"name='{self.name}'")
        if not self.use_bias:
            parts.append("no_bias")
        return ", ".join(parts)
    
    def __repr__(self) -> str:
        """Return a developer-friendly string representation of the layer."""
        return (
            f"VectorOutput(neurons={self.num_neurons}, "
            f"activation={self.activation}, name='{self.name}', "
            f"id='{self.layer_id[:8]}...')"
        )


@dataclass
class GenericOutput(OutputLayer):
    """
    Represents a generic output layer displayed as a rounded box with text.
    
    This output layer is displayed as a rounded box containing text, suitable for
    representing regression outputs, classification outputs, or any output where
    you don't need to show individual neurons. The text is customizable.
    
    Attributes:
        output_size (int): The dimensionality of the output (used for connections).
        text (str): The text to display in the box (e.g., "Regression", "Classification", "Softmax").
        name (Optional[str]): Human-readable name for the layer.
        layer_id (str): Unique identifier for this layer (auto-generated).
    
    Example:
        >>> # Classification output
        >>> output_layer = GenericOutput(output_size=10, text="Classification", name="Output")
        >>> 
        >>> # Regression output
        >>> output_layer = GenericOutput(output_size=1, text="Regression", name="Output")
        >>> 
        >>> # Custom text
        >>> output_layer = GenericOutput(output_size=5, text="Custom Output", name="Output")
    """
    output_size: int
    text: str = "Output"
    name: Optional[str] = None
    layer_id: Optional[str] = None
    
    def __post_init__(self):
        """Validate the layer configuration after initialization."""
        if self.output_size <= 0:
            raise ValueError("Output size must be positive")
        
        if not self.text:
            raise ValueError("Text cannot be empty")
        
        # Initialize the base Layer class
        super().__init__(
            layer_type=LayerType.OUTPUT_GENERIC,
            name=self.name,
            layer_id=self.layer_id
        )
    
    def get_output_size(self) -> int:
        """
        Get the output size of this output layer.
        
        Returns:
            int: The dimensionality of the output.
        """
        return self.output_size
    
    def __str__(self) -> str:
        """Return a human-readable string representation of the layer."""
        parts = [f"GenericOutput(size={self.output_size}, text='{self.text}')"]
        if self.name:
            parts.append(f"name='{self.name}'")
        return ", ".join(parts)
    
    def __repr__(self) -> str:
        """Return a developer-friendly string representation of the layer."""
        return (
            f"GenericOutput(size={self.output_size}, text='{self.text}', "
            f"name='{self.name}', id='{self.layer_id[:8]}...')"
        )


class NeuralNetwork:
    """
    A class to represent and store neural network structure information.
    
    This class holds all relevant information about a neural network's architecture,
    including its layers, connections, name, and type. It serves as the foundation
    for visualizing neural network structures.
    
    The network supports both linear (sequential) and non-linear (branching) architectures
    through a parent-child relationship system between layers.
    
    Attributes:
        name (str): The name of the neural network.
        network_type (NetworkType): The type of neural network (e.g., FEEDFORWARD).
        layers (Dict[str, Layer]): Dictionary mapping layer IDs to Layer objects.
        connections (Dict[str, List[str]]): Maps parent layer IDs to lists of child layer IDs.
        description (Optional[str]): Optional description of the network.
        metadata (Dict[str, Any]): Additional metadata about the network.
    
    Example:
        >>> nn = NeuralNetwork(
        ...     name="My Classifier",
        ...     network_type=NetworkType.FEEDFORWARD
        ... )
        >>> input_id = nn.add_layer(FullyConnectedLayer(num_neurons=784, name="Input"))
        >>> hidden_id = nn.add_layer(FullyConnectedLayer(num_neurons=128, activation="relu", name="Hidden1"))
        >>> output_id = nn.add_layer(FullyConnectedLayer(num_neurons=10, activation="softmax", name="Output"))
    """
    
    def __init__(
        self,
        name: str,
        network_type: NetworkType = NetworkType.FEEDFORWARD,
        description: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize a NeuralNetwork object.
        
        Args:
            name (str): The name of the neural network.
            network_type (NetworkType): The type of neural network. Defaults to FEEDFORWARD.
            description (Optional[str]): Optional description of the network.
            metadata (Optional[Dict[str, Any]]): Additional metadata about the network.
        """
        self.name = name
        self.network_type = network_type
        self.description = description
        self.metadata = metadata or {}
        self.layers: Dict[str, Layer] = {}  # layer_id -> Layer
        self.connections: Dict[str, List[str]] = {}  # parent_id -> [child_ids]
        self._layer_order: List[str] = []  # Maintains insertion order for linear networks
    
    def add_layer(
        self, 
        layer: Layer, 
        parent_ids: Optional[List[str]] = None,
        is_input: bool = False
    ) -> str:
        """
        Add a layer to the neural network.
        
        If parent_ids is None and the network already has layers, the new layer
        will be connected to the last added layer (linear/sequential structure).
        If parent_ids is provided, the layer will be connected to the specified parent(s).
        If the network is empty, the layer becomes the first layer with no parents.
        Use is_input=True to create an independent input layer (no parents) for multi-input networks.
        
        Args:
            layer (Layer): The layer object to add (e.g., FullyConnectedLayer).
            parent_ids (Optional[List[str]]): List of parent layer IDs. 
                If None and network is not empty, connects to the last layer.
                If None and network is empty, creates the first layer with no parents.
            is_input (bool): If True, creates an independent input layer with no parents.
                Use this for multi-input networks where you need multiple root layers.
                Equivalent to passing parent_ids=[].
        
        Returns:
            str: The unique ID of the added layer.
            
        Raises:
            ValueError: If a specified parent layer ID doesn't exist.
            TypeError: If layer is not an instance of Layer.
        """
        # Validate that layer is a Layer instance
        if not isinstance(layer, Layer):
            raise TypeError(f"Layer must be an instance of Layer, got {type(layer).__name__}")
        
        # Add the layer to the dictionary
        layer_id = layer.layer_id
        self.layers[layer_id] = layer
        self._layer_order.append(layer_id)
        
        # Handle connections
        # Automatically detect InputLayer types (VectorInput, ImageInput, etc.)
        is_input_layer = getattr(layer, 'is_input_layer', False)
        
        if is_input or is_input_layer:
            # Explicitly create an independent input layer (no parents)
            parent_ids = []
        elif parent_ids is None:
            # Linear structure: connect to the last layer if one exists
            if len(self._layer_order) > 1:
                parent_id = self._layer_order[-2]  # The previous layer
                parent_ids = [parent_id]
            else:
                # First layer, no parents
                parent_ids = []
        
        # Validate and create connections
        for parent_id in parent_ids:
            if parent_id not in self.layers:
                raise ValueError(f"Parent layer ID '{parent_id}' does not exist")
            
            # Add this layer as a child of the parent
            if parent_id not in self.connections:
                self.connections[parent_id] = []
            self.connections[parent_id].append(layer_id)
        
        return layer_id
    
    def get_parents(self, layer_id: str) -> List[str]:
        """
        Get the parent layer IDs for a given layer.
        
        Args:
            layer_id (str): The ID of the layer to query.
            
        Returns:
            List[str]: List of parent layer IDs.
            
        Raises:
            ValueError: If the layer ID doesn't exist.
        """
        if layer_id not in self.layers:
            raise ValueError(f"Layer ID '{layer_id}' does not exist")
        
        parents = []
        for parent_id, children in self.connections.items():
            if layer_id in children:
                parents.append(parent_id)
        return parents
    
    def get_children(self, layer_id: str) -> List[str]:
        """
        Get the child layer IDs for a given layer.
        
        Args:
            layer_id (str): The ID of the layer to query.
            
        Returns:
            List[str]: List of child layer IDs.
            
        Raises:
            ValueError: If the layer ID doesn't exist.
        """
        if layer_id not in self.layers:
            raise ValueError(f"Layer ID '{layer_id}' does not exist")
        
        return self.connections.get(layer_id, [])
    
    def get_root_layers(self) -> List[str]:
        """
        Get all root layers (layers with no parents).
        
        Returns:
            List[str]: List of root layer IDs.
        """
        all_children = set()
        for children in self.connections.values():
            all_children.update(children)
        
        root_layers = [layer_id for layer_id in self.layers.keys() 
                      if layer_id not in all_children]
        return root_layers
    
    def has_input_layer(self) -> bool:
        """
        Check if the network has at least one input layer.
        
        An input layer is defined as either:
        - A layer that inherits from InputLayer (e.g., VectorInput)
        - A root layer (layer with no parents)
        
        Returns:
            bool: True if the network has at least one input layer.
        """
        root_layers = self.get_root_layers()
        return len(root_layers) > 0
    
    def get_input_layers(self) -> List[str]:
        """
        Get all input layers in the network.
        
        Input layers are root layers (layers with no parents), which includes
        both VectorInput layers and any FullyConnectedLayer added as the first
        layer or with is_input=True.
        
        Returns:
            List[str]: List of input layer IDs.
        """
        return self.get_root_layers()
    
    def has_output_layer(self) -> bool:
        """
        Check if the network has at least one output layer.
        
        An output layer is defined as either:
        - A layer that inherits from OutputLayer (e.g., VectorOutput, GenericOutput)
        - A leaf layer (layer with no children)
        
        Returns:
            bool: True if the network has at least one output layer.
        """
        leaf_layers = self.get_leaf_layers()
        return len(leaf_layers) > 0
    
    def get_output_layers(self) -> List[str]:
        """
        Get all output layers in the network.
        
        Output layers are leaf layers (layers with no children), which includes
        VectorOutput, GenericOutput, and any FullyConnectedLayer added as the last
        layer.
        
        Returns:
            List[str]: List of output layer IDs.
        """
        return self.get_leaf_layers()
    
    def get_leaf_layers(self) -> List[str]:
        """
        Get all leaf layers (layers with no children).
        
        Returns:
            List[str]: List of leaf layer IDs.
        """
        return [layer_id for layer_id in self.layers.keys() 
                if layer_id not in self.connections or len(self.connections[layer_id]) == 0]
    
    def remove_layer(self, layer_id: str) -> None:
        """
        Remove a layer from the neural network by its ID.
        
        This will also remove all connections involving this layer.
        
        Args:
            layer_id (str): The ID of the layer to remove.
            
        Raises:
            ValueError: If the layer ID doesn't exist.
        """
        if layer_id not in self.layers:
            raise ValueError(f"Layer ID '{layer_id}' does not exist")
        
        # Remove the layer
        del self.layers[layer_id]
        self._layer_order.remove(layer_id)
        
        # Remove from connections (as parent)
        if layer_id in self.connections:
            del self.connections[layer_id]
        
        # Remove from connections (as child)
        for parent_id in list(self.connections.keys()):
            if layer_id in self.connections[parent_id]:
                self.connections[parent_id].remove(layer_id)
                # Clean up empty connection lists
                if not self.connections[parent_id]:
                    del self.connections[parent_id]
    
    def get_layer(self, layer_id: str) -> Layer:
        """
        Get layer object by ID.
        
        Args:
            layer_id (str): The ID of the layer to retrieve.
            
        Returns:
            Layer: The layer object.
            
        Raises:
            ValueError: If the layer ID doesn't exist.
        """
        if layer_id not in self.layers:
            raise ValueError(f"Layer ID '{layer_id}' does not exist")
        return self.layers[layer_id]
    
    def get_layer_by_name(self, name: str) -> Optional[Layer]:
        """
        Get layer object by name.
        
        Args:
            name (str): The name of the layer to retrieve.
            
        Returns:
            Optional[Layer]: The layer object, or None if not found.
        """
        for layer in self.layers.values():
            if layer.name == name:
                return layer
        return None
    
    def get_layer_id_by_name(self, name: str) -> Optional[str]:
        """
        Get layer ID by name.
        
        Args:
            name (str): The name of the layer.
            
        Returns:
            Optional[str]: The layer ID, or None if not found.
        """
        for layer_id, layer in self.layers.items():
            if layer.name == name:
                return layer_id
        return None
    
    def num_layers(self) -> int:
        """
        Get the total number of layers in the network.
        
        Returns:
            int: The number of layers.
        """
        return len(self.layers)
    
    def get_total_neurons(self) -> int:
        """
        Calculate the total number of neurons across all layers.
        
        For fully connected layers, this counts the number of neurons.
        For other layer types, it counts the output size.
        
        Returns:
            int: Total number of output units across all layers.
        """
        return sum(layer.get_output_size() for layer in self.layers.values())
    
    def is_linear(self) -> bool:
        """
        Check if the network has a linear (sequential) structure.
        
        A network is considered linear if each layer (except the first) has exactly
        one parent, and each layer (except the last) has exactly one child.
        
        Returns:
            bool: True if the network is linear, False otherwise.
        """
        if len(self.layers) == 0:
            return True
        
        # Check that there's exactly one root
        roots = self.get_root_layers()
        if len(roots) != 1:
            return False
        
        # Check that each layer has at most one child and one parent
        for layer_id in self.layers.keys():
            children = self.get_children(layer_id)
            parents = self.get_parents(layer_id)
            
            if len(children) > 1 or len(parents) > 1:
                return False
        
        return True
    
    def __repr__(self) -> str:
        """Return a string representation of the neural network."""
        return (
            f"NeuralNetwork(name='{self.name}', "
            f"type={self.network_type.value}, "
            f"layers={self.num_layers()}, "
            f"total_neurons={self.get_total_neurons()}, "
            f"linear={self.is_linear()})"
        )
    
    def __str__(self) -> str:
        """Return a human-readable string representation of the neural network."""
        lines = [
            f"Neural Network: {self.name}",
            f"Type: {self.network_type.value}",
            f"Structure: {'Linear' if self.is_linear() else 'Non-linear (branching)'}",
            f"Total Layers: {self.num_layers()}",
            f"Total Output Units: {self.get_total_neurons()}"
        ]
        
        if self.description:
            lines.append(f"Description: {self.description}")
        
        if self.layers:
            lines.append("\nLayers:")
            for i, layer_id in enumerate(self._layer_order):
                layer = self.layers[layer_id]
                
                # Build layer description
                layer_str = f"  Layer {i}: "
                
                # Use the layer's __str__ method for type-specific info
                if isinstance(layer, FullyConnectedLayer):
                    layer_str += f"{layer.get_output_size()} neurons"
                    if layer.name:
                        layer_str += f" ('{layer.name}')"
                    if layer.activation:
                        layer_str += f" - activation: {layer.activation}"
                    layer_str += f" - type: {layer.layer_type.value}"
                else:
                    # For future layer types
                    layer_str += str(layer)
                
                # Show parent information
                parents = self.get_parents(layer_id)
                if parents:
                    parent_names = []
                    for parent_id in parents:
                        parent_layer = self.layers[parent_id]
                        parent_names.append(parent_layer.name if parent_layer.name else f"Layer {self._layer_order.index(parent_id)}")
                    layer_str += f" <- parents: [{', '.join(parent_names)}]"
                
                # Show children information
                children = self.get_children(layer_id)
                if children:
                    child_names = []
                    for child_id in children:
                        child_layer = self.layers[child_id]
                        child_names.append(child_layer.name if child_layer.name else f"Layer {self._layer_order.index(child_id)}")
                    layer_str += f" -> children: [{', '.join(child_names)}]"
                
                lines.append(layer_str)
        
        return "\n".join(lines)
    
    def summary(self) -> str:
        """
        Generate a summary of the neural network architecture.
        
        Returns:
            str: A formatted summary of the network.
        """
        return str(self)
